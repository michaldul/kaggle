{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dimen(dataset,column,toreplace):\n",
    "    for index,i in dataset[column].duplicated(keep=False).iteritems():\n",
    "        if i==False:\n",
    "            dataset.set_value(index,column,toreplace)\n",
    "    return dataset\n",
    "    \n",
    "def act_data_treatment(dsname):\n",
    "    dataset = dsname\n",
    "    \n",
    "    for col in list(dataset.columns):\n",
    "        if col not in ['people_id', 'activity_id', 'date', 'char_38', 'outcome']:\n",
    "            if dataset[col].dtype == 'object':\n",
    "                dataset[col].fillna('type 0', inplace=True)\n",
    "                dataset[col] = dataset[col].apply(lambda x: x.split(' ')[1]).astype(np.int32)\n",
    "            elif dataset[col].dtype == 'bool':\n",
    "                dataset[col] = dataset[col].astype(np.int8)\n",
    "    \n",
    "    dataset['year'] = dataset['date'].dt.year\n",
    "    dataset['month'] = dataset['date'].dt.month\n",
    "    dataset['day'] = dataset['date'].dt.day\n",
    "    dataset['isweekend'] = (dataset['date'].dt.weekday >= 5).astype(int)\n",
    "    dataset = dataset.drop('date', axis = 1)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (2197291, 14)\n",
      "Test data shape: (498687, 13)\n",
      "People data shape: (189118, 41)\n"
     ]
    }
   ],
   "source": [
    "act_train_data = pd.read_csv(\"input/act_train.csv\",dtype={'people_id': np.str, 'activity_id': np.str, 'outcome': np.int8}, parse_dates=['date'])\n",
    "act_test_data  = pd.read_csv(\"input/act_test.csv\", dtype={'people_id': np.str, 'activity_id': np.str}, parse_dates=['date'])\n",
    "people_data    = pd.read_csv(\"input/people.csv\", dtype={'people_id': np.str, 'activity_id': np.str, 'char_38': np.int32}, parse_dates=['date'])\n",
    "\n",
    "act_train_data=act_train_data.drop('char_10',axis=1)\n",
    "act_test_data=act_test_data.drop('char_10',axis=1)\n",
    "\n",
    "print(\"Train data shape: \" + format(act_train_data.shape))\n",
    "print(\"Test data shape: \" + format(act_test_data.shape))\n",
    "print(\"People data shape: \" + format(people_data.shape))\n",
    "act_train_data  = act_data_treatment(act_train_data)\n",
    "act_test_data   = act_data_treatment(act_test_data)\n",
    "people_data = act_data_treatment(people_data)\n",
    "\n",
    "train = act_train_data.merge(people_data, on='people_id', how='left', left_index=True)\n",
    "test  = act_test_data.merge(people_data, on='people_id', how='left', left_index=True)\n",
    "\n",
    "del act_train_data\n",
    "del act_test_data\n",
    "del people_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (2197291, 31271)\n",
      "Test data: (498687, 31271)\n",
      "###########\n",
      "One Hot enconded Test Dataset Script\n"
     ]
    }
   ],
   "source": [
    "train=train.sort_values(['people_id'], ascending=[1])\n",
    "test=test.sort_values(['people_id'], ascending=[1])\n",
    "\n",
    "train_columns = train.columns.values\n",
    "test_columns = test.columns.values\n",
    "features = list(set(train_columns) & set(test_columns))\n",
    "\n",
    "train.fillna('NA', inplace=True)\n",
    "test.fillna('NA', inplace=True)\n",
    "\n",
    "y = train.outcome\n",
    "train=train.drop('outcome',axis=1)\n",
    "\n",
    "whole=pd.concat([train,test],ignore_index=True)\n",
    "categorical=['group_1','activity_category','char_1_x','char_2_x','char_3_x','char_4_x','char_5_x','char_6_x','char_7_x','char_8_x','char_9_x','char_2_y','char_3_y','char_4_y','char_5_y','char_6_y','char_7_y','char_8_y','char_9_y']\n",
    "for category in categorical:\n",
    "    whole=reduce_dimen(whole,category,9999999)\n",
    "    \n",
    "X=whole[:len(train)]\n",
    "X_test=whole[len(train):]\n",
    "\n",
    "del train\n",
    "del whole\n",
    "    \n",
    "X=X.sort_values(['people_id'], ascending=[1])\n",
    "\n",
    "X = X[features].drop(['people_id', 'activity_id'], axis = 1)\n",
    "X_test = X_test[features].drop(['people_id', 'activity_id'], axis = 1)\n",
    "\n",
    "categorical=['group_1','activity_category','char_1_x','char_2_x','char_3_x','char_4_x','char_5_x','char_6_x','char_7_x','char_8_x','char_9_x','char_2_y','char_3_y','char_4_y','char_5_y','char_6_y','char_7_y','char_8_y','char_9_y']\n",
    "not_categorical=[]\n",
    "for category in X.columns:\n",
    "    if category not in categorical:\n",
    "        not_categorical.append(category)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc=enc.fit(pd.concat([X[categorical],X_test[categorical]]))\n",
    "X_cat_sparse=enc.transform(X[categorical])\n",
    "X_test_cat_sparse=enc.transform(X_test[categorical])\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "X_sparse=hstack((X[not_categorical], X_cat_sparse))\n",
    "X_test_sparse=hstack((X_test[not_categorical], X_test_cat_sparse))\n",
    "\n",
    "print(\"Training data: \" + format(X_sparse.shape))\n",
    "print(\"Test data: \" + format(X_test_sparse.shape))\n",
    "print(\"###########\")\n",
    "print(\"One Hot enconded Test Dataset Script\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until train error hasn't decreased in 10 rounds.\n",
      "[0]\ttrain-auc:0.886709\n",
      "[1]\ttrain-auc:0.894866\n",
      "[2]\ttrain-auc:0.903151\n",
      "[3]\ttrain-auc:0.911677\n",
      "[4]\ttrain-auc:0.920117\n",
      "[5]\ttrain-auc:0.928126\n",
      "[6]\ttrain-auc:0.935514\n",
      "[7]\ttrain-auc:0.942300\n",
      "[8]\ttrain-auc:0.948593\n",
      "[9]\ttrain-auc:0.954416\n",
      "[10]\ttrain-auc:0.959757\n",
      "[11]\ttrain-auc:0.964574\n",
      "[12]\ttrain-auc:0.968845\n",
      "[13]\ttrain-auc:0.972559\n",
      "[14]\ttrain-auc:0.975752\n",
      "[15]\ttrain-auc:0.978464\n",
      "[16]\ttrain-auc:0.980752\n",
      "[17]\ttrain-auc:0.982674\n",
      "[18]\ttrain-auc:0.984283\n",
      "[19]\ttrain-auc:0.985627\n",
      "[20]\ttrain-auc:0.986753\n",
      "[21]\ttrain-auc:0.987704\n",
      "[22]\ttrain-auc:0.988512\n",
      "[23]\ttrain-auc:0.989206\n",
      "[24]\ttrain-auc:0.989810\n",
      "[25]\ttrain-auc:0.990341\n",
      "[26]\ttrain-auc:0.990813\n",
      "[27]\ttrain-auc:0.991236\n",
      "[28]\ttrain-auc:0.991617\n",
      "[29]\ttrain-auc:0.991963\n",
      "[30]\ttrain-auc:0.992278\n",
      "[31]\ttrain-auc:0.992567\n",
      "[32]\ttrain-auc:0.992832\n",
      "[33]\ttrain-auc:0.993075\n",
      "[34]\ttrain-auc:0.993300\n",
      "[35]\ttrain-auc:0.993508\n",
      "[36]\ttrain-auc:0.993702\n",
      "[37]\ttrain-auc:0.993881\n",
      "[38]\ttrain-auc:0.994049\n",
      "[39]\ttrain-auc:0.994206\n",
      "[40]\ttrain-auc:0.994353\n",
      "[41]\ttrain-auc:0.994491\n",
      "[42]\ttrain-auc:0.994620\n",
      "[43]\ttrain-auc:0.994742\n",
      "[44]\ttrain-auc:0.994856\n",
      "[45]\ttrain-auc:0.994964\n",
      "[46]\ttrain-auc:0.995067\n",
      "[47]\ttrain-auc:0.995163\n",
      "[48]\ttrain-auc:0.995254\n",
      "[49]\ttrain-auc:0.995341\n",
      "[50]\ttrain-auc:0.995423\n",
      "[51]\ttrain-auc:0.995500\n",
      "[52]\ttrain-auc:0.995574\n",
      "[53]\ttrain-auc:0.995644\n",
      "[54]\ttrain-auc:0.995710\n",
      "[55]\ttrain-auc:0.995773\n",
      "[56]\ttrain-auc:0.995834\n",
      "[57]\ttrain-auc:0.995891\n",
      "[58]\ttrain-auc:0.995946\n",
      "[59]\ttrain-auc:0.995998\n",
      "[60]\ttrain-auc:0.996047\n",
      "[61]\ttrain-auc:0.996095\n",
      "[62]\ttrain-auc:0.996140\n",
      "[63]\ttrain-auc:0.996183\n",
      "[64]\ttrain-auc:0.996224\n",
      "[65]\ttrain-auc:0.996264\n",
      "[66]\ttrain-auc:0.996302\n",
      "[67]\ttrain-auc:0.996338\n",
      "[68]\ttrain-auc:0.996373\n",
      "[69]\ttrain-auc:0.996406\n",
      "[70]\ttrain-auc:0.996438\n",
      "[71]\ttrain-auc:0.996469\n",
      "[72]\ttrain-auc:0.996498\n",
      "[73]\ttrain-auc:0.996527\n",
      "[74]\ttrain-auc:0.996554\n",
      "[75]\ttrain-auc:0.996579\n",
      "[76]\ttrain-auc:0.996604\n",
      "[77]\ttrain-auc:0.996628\n",
      "[78]\ttrain-auc:0.996651\n",
      "[79]\ttrain-auc:0.996673\n",
      "[80]\ttrain-auc:0.996694\n",
      "[81]\ttrain-auc:0.996715\n",
      "[82]\ttrain-auc:0.996734\n",
      "[83]\ttrain-auc:0.996753\n",
      "[84]\ttrain-auc:0.996771\n",
      "[85]\ttrain-auc:0.996788\n",
      "[86]\ttrain-auc:0.996804\n",
      "[87]\ttrain-auc:0.996820\n",
      "[88]\ttrain-auc:0.996835\n",
      "[89]\ttrain-auc:0.996849\n",
      "[90]\ttrain-auc:0.996863\n",
      "[91]\ttrain-auc:0.996876\n",
      "[92]\ttrain-auc:0.996889\n",
      "[93]\ttrain-auc:0.996901\n",
      "[94]\ttrain-auc:0.996913\n",
      "[95]\ttrain-auc:0.996924\n",
      "[96]\ttrain-auc:0.996934\n",
      "[97]\ttrain-auc:0.996944\n",
      "[98]\ttrain-auc:0.996954\n",
      "[99]\ttrain-auc:0.996963\n",
      "[100]\ttrain-auc:0.996972\n",
      "[101]\ttrain-auc:0.996981\n",
      "[102]\ttrain-auc:0.996989\n",
      "[103]\ttrain-auc:0.996997\n",
      "[104]\ttrain-auc:0.997005\n",
      "[105]\ttrain-auc:0.997012\n",
      "[106]\ttrain-auc:0.997019\n",
      "[107]\ttrain-auc:0.997026\n",
      "[108]\ttrain-auc:0.997032\n",
      "[109]\ttrain-auc:0.997038\n",
      "[110]\ttrain-auc:0.997044\n",
      "[111]\ttrain-auc:0.997050\n",
      "[112]\ttrain-auc:0.997056\n",
      "[113]\ttrain-auc:0.997061\n",
      "[114]\ttrain-auc:0.997066\n",
      "[115]\ttrain-auc:0.997071\n",
      "[116]\ttrain-auc:0.997076\n",
      "[117]\ttrain-auc:0.997081\n",
      "[118]\ttrain-auc:0.997085\n",
      "[119]\ttrain-auc:0.997090\n",
      "[120]\ttrain-auc:0.997094\n",
      "[121]\ttrain-auc:0.997098\n",
      "[122]\ttrain-auc:0.997102\n",
      "[123]\ttrain-auc:0.997106\n",
      "[124]\ttrain-auc:0.997109\n",
      "[125]\ttrain-auc:0.997113\n",
      "[126]\ttrain-auc:0.997117\n",
      "[127]\ttrain-auc:0.997120\n",
      "[128]\ttrain-auc:0.997123\n",
      "[129]\ttrain-auc:0.997126\n",
      "[130]\ttrain-auc:0.997129\n",
      "[131]\ttrain-auc:0.997132\n",
      "[132]\ttrain-auc:0.997135\n",
      "[133]\ttrain-auc:0.997138\n",
      "[134]\ttrain-auc:0.997140\n",
      "[135]\ttrain-auc:0.997143\n",
      "[136]\ttrain-auc:0.997145\n",
      "[137]\ttrain-auc:0.997148\n",
      "[138]\ttrain-auc:0.997150\n",
      "[139]\ttrain-auc:0.997152\n",
      "[140]\ttrain-auc:0.997154\n",
      "[141]\ttrain-auc:0.997157\n",
      "[142]\ttrain-auc:0.997159\n",
      "[143]\ttrain-auc:0.997161\n",
      "[144]\ttrain-auc:0.997163\n",
      "[145]\ttrain-auc:0.997164\n",
      "[146]\ttrain-auc:0.997166\n",
      "[147]\ttrain-auc:0.997168\n",
      "[148]\ttrain-auc:0.997170\n",
      "[149]\ttrain-auc:0.997171\n",
      "[150]\ttrain-auc:0.997173\n",
      "[151]\ttrain-auc:0.997174\n",
      "[152]\ttrain-auc:0.997176\n",
      "[153]\ttrain-auc:0.997177\n",
      "[154]\ttrain-auc:0.997179\n",
      "[155]\ttrain-auc:0.997180\n",
      "[156]\ttrain-auc:0.997181\n",
      "[157]\ttrain-auc:0.997183\n",
      "[158]\ttrain-auc:0.997184\n",
      "[159]\ttrain-auc:0.997185\n",
      "[160]\ttrain-auc:0.997186\n",
      "[161]\ttrain-auc:0.997188\n",
      "[162]\ttrain-auc:0.997189\n",
      "[163]\ttrain-auc:0.997190\n",
      "[164]\ttrain-auc:0.997191\n",
      "[165]\ttrain-auc:0.997192\n",
      "[166]\ttrain-auc:0.997193\n",
      "[167]\ttrain-auc:0.997194\n",
      "[168]\ttrain-auc:0.997195\n",
      "[169]\ttrain-auc:0.997195\n",
      "[170]\ttrain-auc:0.997196\n",
      "[171]\ttrain-auc:0.997197\n",
      "[172]\ttrain-auc:0.997198\n",
      "[173]\ttrain-auc:0.997199\n",
      "[174]\ttrain-auc:0.997199\n",
      "[175]\ttrain-auc:0.997200\n",
      "[176]\ttrain-auc:0.997201\n",
      "[177]\ttrain-auc:0.997202\n",
      "[178]\ttrain-auc:0.997202\n",
      "[179]\ttrain-auc:0.997203\n",
      "[180]\ttrain-auc:0.997204\n",
      "[181]\ttrain-auc:0.997204\n",
      "[182]\ttrain-auc:0.997205\n",
      "[183]\ttrain-auc:0.997205\n",
      "[184]\ttrain-auc:0.997206\n",
      "[185]\ttrain-auc:0.997206\n",
      "[186]\ttrain-auc:0.997207\n",
      "[187]\ttrain-auc:0.997207\n",
      "[188]\ttrain-auc:0.997208\n",
      "[189]\ttrain-auc:0.997208\n",
      "[190]\ttrain-auc:0.997209\n",
      "[191]\ttrain-auc:0.997209\n",
      "[192]\ttrain-auc:0.997210\n",
      "[193]\ttrain-auc:0.997210\n",
      "[194]\ttrain-auc:0.997210\n",
      "[195]\ttrain-auc:0.997211\n",
      "[196]\ttrain-auc:0.997211\n",
      "[197]\ttrain-auc:0.997212\n",
      "[198]\ttrain-auc:0.997212\n",
      "[199]\ttrain-auc:0.997212\n",
      "[200]\ttrain-auc:0.997213\n",
      "[201]\ttrain-auc:0.997213\n",
      "[202]\ttrain-auc:0.997213\n",
      "[203]\ttrain-auc:0.997214\n",
      "[204]\ttrain-auc:0.997214\n",
      "[205]\ttrain-auc:0.997214\n",
      "[206]\ttrain-auc:0.997214\n",
      "[207]\ttrain-auc:0.997215\n",
      "[208]\ttrain-auc:0.997215\n",
      "[209]\ttrain-auc:0.997215\n",
      "[210]\ttrain-auc:0.997216\n",
      "[211]\ttrain-auc:0.997216\n",
      "[212]\ttrain-auc:0.997216\n",
      "[213]\ttrain-auc:0.997216\n",
      "[214]\ttrain-auc:0.997217\n",
      "[215]\ttrain-auc:0.997217\n",
      "[216]\ttrain-auc:0.997217\n",
      "[217]\ttrain-auc:0.997217\n",
      "[218]\ttrain-auc:0.997218\n",
      "[219]\ttrain-auc:0.997218\n",
      "[220]\ttrain-auc:0.997218\n",
      "[221]\ttrain-auc:0.997218\n",
      "[222]\ttrain-auc:0.997218\n",
      "[223]\ttrain-auc:0.997219\n",
      "[224]\ttrain-auc:0.997219\n",
      "[225]\ttrain-auc:0.997219\n",
      "[226]\ttrain-auc:0.997219\n",
      "[227]\ttrain-auc:0.997220\n",
      "[228]\ttrain-auc:0.997220\n",
      "[229]\ttrain-auc:0.997220\n",
      "[230]\ttrain-auc:0.997220\n",
      "[231]\ttrain-auc:0.997220\n",
      "[232]\ttrain-auc:0.997221\n",
      "[233]\ttrain-auc:0.997221\n",
      "[234]\ttrain-auc:0.997221\n",
      "[235]\ttrain-auc:0.997221\n",
      "[236]\ttrain-auc:0.997221\n",
      "[237]\ttrain-auc:0.997221\n",
      "[238]\ttrain-auc:0.997222\n",
      "[239]\ttrain-auc:0.997222\n",
      "[240]\ttrain-auc:0.997222\n",
      "[241]\ttrain-auc:0.997222\n",
      "[242]\ttrain-auc:0.997222\n",
      "[243]\ttrain-auc:0.997222\n",
      "[244]\ttrain-auc:0.997223\n",
      "[245]\ttrain-auc:0.997223\n",
      "[246]\ttrain-auc:0.997223\n",
      "[247]\ttrain-auc:0.997223\n",
      "[248]\ttrain-auc:0.997223\n",
      "[249]\ttrain-auc:0.997223\n",
      "[250]\ttrain-auc:0.997223\n",
      "[251]\ttrain-auc:0.997224\n",
      "[252]\ttrain-auc:0.997224\n",
      "[253]\ttrain-auc:0.997224\n",
      "[254]\ttrain-auc:0.997224\n",
      "[255]\ttrain-auc:0.997224\n",
      "[256]\ttrain-auc:0.997224\n",
      "[257]\ttrain-auc:0.997225\n",
      "[258]\ttrain-auc:0.997225\n",
      "[259]\ttrain-auc:0.997225\n",
      "[260]\ttrain-auc:0.997225\n",
      "[261]\ttrain-auc:0.997225\n",
      "[262]\ttrain-auc:0.997225\n",
      "[263]\ttrain-auc:0.997225\n",
      "[264]\ttrain-auc:0.997225\n",
      "[265]\ttrain-auc:0.997226\n",
      "[266]\ttrain-auc:0.997226\n",
      "[267]\ttrain-auc:0.997226\n",
      "[268]\ttrain-auc:0.997226\n",
      "[269]\ttrain-auc:0.997226\n",
      "[270]\ttrain-auc:0.997226\n",
      "[271]\ttrain-auc:0.997226\n",
      "[272]\ttrain-auc:0.997226\n",
      "[273]\ttrain-auc:0.997227\n",
      "[274]\ttrain-auc:0.997227\n",
      "[275]\ttrain-auc:0.997227\n",
      "[276]\ttrain-auc:0.997227\n",
      "[277]\ttrain-auc:0.997227\n",
      "[278]\ttrain-auc:0.997227\n",
      "[279]\ttrain-auc:0.997227\n",
      "[280]\ttrain-auc:0.997227\n",
      "[281]\ttrain-auc:0.997227\n",
      "[282]\ttrain-auc:0.997227\n",
      "[283]\ttrain-auc:0.997228\n",
      "[284]\ttrain-auc:0.997228\n",
      "[285]\ttrain-auc:0.997228\n",
      "[286]\ttrain-auc:0.997228\n",
      "[287]\ttrain-auc:0.997228\n",
      "[288]\ttrain-auc:0.997228\n",
      "[289]\ttrain-auc:0.997228\n",
      "[290]\ttrain-auc:0.997228\n",
      "[291]\ttrain-auc:0.997228\n",
      "[292]\ttrain-auc:0.997229\n",
      "[293]\ttrain-auc:0.997229\n",
      "[294]\ttrain-auc:0.997229\n",
      "[295]\ttrain-auc:0.997229\n",
      "[296]\ttrain-auc:0.997229\n",
      "[297]\ttrain-auc:0.997229\n",
      "[298]\ttrain-auc:0.997229\n",
      "[299]\ttrain-auc:0.997229\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_sparse,label=y)\n",
    "dtest = xgb.DMatrix(X_test_sparse)\n",
    "\n",
    "param = {'max_depth':10, 'eta':0.02, 'silent':1, 'objective':'binary:logistic' }\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "param['subsample'] = 0.7\n",
    "param['colsample_bytree']= 0.7\n",
    "param['min_child_weight'] = 0\n",
    "param['booster'] = \"gblinear\"\n",
    "\n",
    "watchlist  = [(dtrain,'train')]\n",
    "num_round = 300\n",
    "early_stopping_rounds=10\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist,early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "ypred = bst.predict(dtest)\n",
    "output = pd.DataFrame({ 'activity_id' : test['activity_id'], 'outcome': ypred })\n",
    "output.head()\n",
    "output.to_csv('without_leak.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
